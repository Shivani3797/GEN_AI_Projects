{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 📌 Problem Statement\n",
        "\n",
        "Understanding complex insurance policies is challenging due to lengthy and jargon-heavy documents. Customers and agents struggle to find specific information quickly.\n",
        "\n",
        "### **Objective**\n",
        "- Build an AI-powered system to **answer insurance-related queries** efficiently.\n",
        "- Utilize **Retrieval-Augmented Generation (RAG)** to retrieve relevant policy sections.\n",
        "- Use **GPT-4** to generate precise, user-friendly responses.\n",
        "\n",
        "### **Expected Outcome**\n",
        "- **Faster query resolution** for policyholders.\n",
        "- **Improved comprehension** of insurance terms.\n",
        "- **Enhanced customer support** with AI-powered assistance.\n"
      ],
      "metadata": {
        "id": "Wvc173vpdWlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ Flow for Generative Search with RAG\n",
        "\n",
        "## 📂 Load PDF & Extract Text\n",
        "- Read the PDF document.\n",
        "- Extract text content from the pages.\n",
        "- Extract tables (if applicable).\n",
        "\n",
        "## ✂️ Chunk the Extracted Text\n",
        "- Use **RecursiveCharacterTextSplitter** for text chunking.\n",
        "- Ensure each chunk is of **optimal size** (e.g., 500 tokens with some overlap).\n",
        "- Store in a **structured format** (e.g., a DataFrame).\n",
        "\n",
        "## 🔢 Generate Embeddings\n",
        "- Initialize **OpenAIEmbeddings** correctly.\n",
        "- Convert text chunks into **vector embeddings**.\n",
        "\n",
        "## 🗄️ Store in ChromaDB\n",
        "- Persist embeddings and document chunks in **ChromaDB**.\n",
        "- Ensure embeddings are **stored properly** without corruption.\n",
        "\n",
        "## 🔍 Retrieve Relevant Documents using Embeddings\n",
        "- Use the **query** to perform a **similarity search** in ChromaDB.\n",
        "- Retrieve the **top k** most relevant document chunks.\n",
        "\n",
        "## 📊 Rerank Results using Cross-Encoder\n",
        "- Pass retrieved **document-query pairs** through a **cross-encoder**.\n",
        "- Sort results by **relevance scores**.\n",
        "\n",
        "## 📝 Generate Final Answer using GPT\n",
        "- Use the **top reranked results** as **context**.\n",
        "- Format the **prompt** correctly for GPT.\n",
        "- Generate a **coherent, well-structured answer**.\n"
      ],
      "metadata": {
        "id": "ahZR8NbdccY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aNDDqcj1cnCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Installing Neccessary Libraries**"
      ],
      "metadata": {
        "id": "F4GWmIvb61qg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_GHWWD16m7DG",
        "outputId": "a815be96-a813-4d90-ae4a-919f0d88bb04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.16.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.16.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53769 sha256=77f0ed36c159a3612e4ce584a549cd68b39e9877bd1afc12fe248df0cd55e984\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, pypdfium2, protobuf, overrides, opentelemetry-util-http, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, posthog, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, build, pdfminer.six, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, nvidia-cusolver-cu12, kubernetes, fastapi, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.8 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 pdfminer.six-20231228 pdfplumber-0.11.5 posthog-3.16.0 protobuf-5.29.3 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.45.3 tiktoken-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "a904385a9f6942a2a3c6b43fe727de34"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install openai chromadb langchain pdfplumber pandas tiktoken sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbSz07qT3DMa",
        "outputId": "40857be5-b8f5-4433-988a-3e5fc038f5b3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF\n",
            "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/300.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/300.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF\n",
            "Successfully installed PyPDF-5.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJRHMWq9wrv_",
        "outputId": "66165467-b9a6-41df-d8c9-ace67a3bcaf4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.64.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading openai-1.64.0-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed openai-1.64.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install --upgrade langchain-community langchain-core langchain\n",
        "\n",
        "# Reinstalling dependencies just in case\n",
        "!pip install openai chromadb langchain pdfplumber pandas tiktoken sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfcDxP7bv8Ji",
        "outputId": "bc1d9b97-6a8b-4b24-f2fb-ceb3ba346d81"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.40)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.64.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.16.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.40)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Importing Neccessary Libraries**"
      ],
      "metadata": {
        "id": "fCvZDojM7bm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "import pandas as pd\n",
        "import openai\n",
        "import tiktoken\n",
        "import chromadb\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from sentence_transformers import CrossEncoder\n"
      ],
      "metadata": {
        "id": "X3vXWsI8rP7t"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/Principal-Sample-Life-Insurance-Policy.pdf\""
      ],
      "metadata": {
        "id": "Srz4tWLQq6Dt"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Extraction**\n",
        "\n",
        "\n",
        "> Text and Tables\n",
        "\n"
      ],
      "metadata": {
        "id": "IpdJgYc38xiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_and_tables(pdf_path, doc_name):\n",
        "    data = []\n",
        "    table_data = []\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_no, page in enumerate(pdf.pages, start=1):\n",
        "            text = page.extract_text() or \"\"  # Extract text\n",
        "\n",
        "            # Extract tables\n",
        "            tables = page.extract_tables()\n",
        "            for table_idx, table in enumerate(tables):\n",
        "                df_table = pd.DataFrame(table)  # Convert table to DataFrame\n",
        "                df_table[\"Page No.\"] = page_no  # Add metadata\n",
        "                df_table[\"Table Index\"] = table_idx\n",
        "                table_data.append(df_table)  # Store extracted table\n",
        "\n",
        "            # Store extracted text\n",
        "            data.append({\n",
        "                \"Page No.\": page_no,\n",
        "                \"Page_Text\": text,\n",
        "                \"Document Name\": doc_name,\n",
        "                \"Text_Length\": len(text),\n",
        "                \"Has_Tables\": bool(tables)\n",
        "            })\n",
        "\n",
        "    text_df = pd.DataFrame(data)  # Store extracted text\n",
        "    tables_df = pd.concat(table_data, ignore_index=True) if table_data else pd.DataFrame()  # Store extracted tables\n",
        "\n",
        "    return text_df, tables_df\n",
        "\n",
        "# Example Usage\n",
        "pdf_path = \"/content/Principal-Sample-Life-Insurance-Policy.pdf\"\n",
        "text_df, tables_df = extract_text_and_tables(pdf_path, \"Group Life Insurance Policy\")\n",
        "\n",
        "# View Extracted Text Data\n",
        "print(\"Extracted Text Data:\")\n",
        "print(text_df.head())\n",
        "\n",
        "# View Extracted Tables\n",
        "if not tables_df.empty:\n",
        "    print(\"\\nExtracted Tables:\")\n",
        "    print(tables_df.head())\n",
        "else:\n",
        "    print(\"\\nNo tables found in the document.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0LCnEM3uRZT",
        "outputId": "7d415b9d-c6b5-40c9-a1a0-8f54ed798727"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text Data:\n",
            "   Page No.                                          Page_Text  \\\n",
            "0         1  DOROTHEA GLAUSE S655\\nRHODE ISLAND JOHN DOE 01...   \n",
            "1         2                 This page left blank intentionally   \n",
            "2         3  POLICY RIDER\\nGROUP INSURANCE\\nPOLICY NO: S655...   \n",
            "3         4                 This page left blank intentionally   \n",
            "4         5  PRINCIPAL LIFE INSURANCE COMPANY\\n(called The ...   \n",
            "\n",
            "                 Document Name  Text_Length  Has_Tables  \n",
            "0  Group Life Insurance Policy          188       False  \n",
            "1  Group Life Insurance Policy           34       False  \n",
            "2  Group Life Insurance Policy         1468       False  \n",
            "3  Group Life Insurance Policy           34       False  \n",
            "4  Group Life Insurance Policy          709       False  \n",
            "\n",
            "No tables found in the document.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Extracted Text DataFrame:\")\n",
        "print(text_df.head())  # Ensure text is extracted\n",
        "\n",
        "print(\"\\nExtracted Chunks DataFrame:\")\n",
        "print(df_exploded.head())  # Ensure text chunking worked\n",
        "\n",
        "print(\"\\nExtracted Tables DataFrame:\")\n",
        "if not tables_df.empty:\n",
        "    print(tables_df.head())\n",
        "else:\n",
        "    print(\"No tables found in the document.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K3xTuNXyYw_",
        "outputId": "ae6e599a-6df0-4851-ef14-aec11910c314"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text DataFrame:\n",
            "   Page No.                                          Page_Text  \\\n",
            "0         1  DOROTHEA GLAUSE S655\\nRHODE ISLAND JOHN DOE 01...   \n",
            "1         2                 This page left blank intentionally   \n",
            "2         3  POLICY RIDER\\nGROUP INSURANCE\\nPOLICY NO: S655...   \n",
            "3         4                 This page left blank intentionally   \n",
            "4         5  PRINCIPAL LIFE INSURANCE COMPANY\\n(called The ...   \n",
            "\n",
            "                 Document Name  Text_Length  Has_Tables  \n",
            "0  Group Life Insurance Policy          188       False  \n",
            "1  Group Life Insurance Policy           34       False  \n",
            "2  Group Life Insurance Policy         1468       False  \n",
            "3  Group Life Insurance Policy           34       False  \n",
            "4  Group Life Insurance Policy          709       False  \n",
            "\n",
            "Extracted Chunks DataFrame:\n",
            "   Page No.                                          Page_Text  \\\n",
            "0         1  DOROTHEA GLAUSE S655\\nRHODE ISLAND JOHN DOE 01...   \n",
            "1         2                 This page left blank intentionally   \n",
            "2         3  POLICY RIDER\\nGROUP INSURANCE\\nPOLICY NO: S655...   \n",
            "3         4                 This page left blank intentionally   \n",
            "4         5  PRINCIPAL LIFE INSURANCE COMPANY\\n(called The ...   \n",
            "\n",
            "                 Document Name  Text_Length  Has_Tables  \\\n",
            "0  Group Life Insurance Policy          188       False   \n",
            "1  Group Life Insurance Policy           34       False   \n",
            "2  Group Life Insurance Policy         1468       False   \n",
            "3  Group Life Insurance Policy           34       False   \n",
            "4  Group Life Insurance Policy          709       False   \n",
            "\n",
            "                                              Chunks  \n",
            "0  DOROTHEA GLAUSE S655 RHODE ISLAND JOHN DOE 01/...  \n",
            "1                 This page left blank intentionally  \n",
            "2  POLICY RIDER GROUP INSURANCE POLICY NO: S655 C...  \n",
            "3                 This page left blank intentionally  \n",
            "4  PRINCIPAL LIFE INSURANCE COMPANY (called The P...  \n",
            "\n",
            "Extracted Tables DataFrame:\n",
            "No tables found in the document.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Chunking Text**"
      ],
      "metadata": {
        "id": "FQVNs8LF9ZqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, max_tokens=500):\n",
        "    \"\"\"\n",
        "    Splits the given text into chunks based on token count while ensuring each chunk\n",
        "    does not exceed the specified max_tokens limit.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The input text to be chunked.\n",
        "        max_tokens (int): The maximum number of tokens allowed in each chunk.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of text chunks.\n",
        "    \"\"\"\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")  # Load tokenizer\n",
        "    words = text.split()  # Split text into words\n",
        "\n",
        "    chunks, chunk = [], []  # Initialize lists for storing chunks\n",
        "    token_count = 0  # Counter for tracking tokens in the current chunk\n",
        "\n",
        "    for word in words:\n",
        "        word_tokens = len(encoding.encode(word))  # Count tokens in the word\n",
        "\n",
        "        # If adding the current word exceeds max_tokens, store the current chunk\n",
        "        if token_count + word_tokens > max_tokens:\n",
        "            chunks.append(\" \".join(chunk))  # Add current chunk to the list\n",
        "            chunk = []  # Reset the chunk\n",
        "            token_count = 0  # Reset token counter\n",
        "\n",
        "        chunk.append(word)  # Add word to the current chunk\n",
        "        token_count += word_tokens  # Update token count\n",
        "\n",
        "    # Add the last chunk if not empty\n",
        "    if chunk:\n",
        "        chunks.append(\" \".join(chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Apply chunking function to the \"Page_Text\" column\n",
        "text_df[\"Chunks\"] = text_df[\"Page_Text\"].apply(lambda text: chunk_text(text))\n",
        "\n",
        "# Explode the dataframe so that each chunk gets its own row\n",
        "df_exploded = text_df.explode(\"Chunks\").reset_index(drop=True)\n",
        "\n",
        "# Display first few rows of the exploded dataframe\n",
        "print(df_exploded.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2WlDmqztl1Q",
        "outputId": "252b2333-7339-4e95-97b0-681b1d78b6f3"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Page No.                                          Page_Text  \\\n",
            "0         1  DOROTHEA GLAUSE S655\\nRHODE ISLAND JOHN DOE 01...   \n",
            "1         2                 This page left blank intentionally   \n",
            "2         3  POLICY RIDER\\nGROUP INSURANCE\\nPOLICY NO: S655...   \n",
            "3         4                 This page left blank intentionally   \n",
            "4         5  PRINCIPAL LIFE INSURANCE COMPANY\\n(called The ...   \n",
            "\n",
            "                 Document Name  Text_Length  Has_Tables  \\\n",
            "0  Group Life Insurance Policy          188       False   \n",
            "1  Group Life Insurance Policy           34       False   \n",
            "2  Group Life Insurance Policy         1468       False   \n",
            "3  Group Life Insurance Policy           34       False   \n",
            "4  Group Life Insurance Policy          709       False   \n",
            "\n",
            "                                              Chunks  \n",
            "0  DOROTHEA GLAUSE S655 RHODE ISLAND JOHN DOE 01/...  \n",
            "1                 This page left blank intentionally  \n",
            "2  POLICY RIDER GROUP INSURANCE POLICY NO: S655 C...  \n",
            "3                 This page left blank intentionally  \n",
            "4  PRINCIPAL LIFE INSURANCE COMPANY (called The P...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Creating Embeddings and Storing in ChromaDB**"
      ],
      "metadata": {
        "id": "jzrMXTjp9omm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API Key\n",
        "with open(\"helpmate_api_key.txt\", \"r\") as file:\n",
        "    openai.api_key = file.read().strip()\n",
        "\n",
        "# Initialize the OpenAI client with the API key.\n",
        "client = openai.OpenAI(api_key=openai.api_key)\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "# Initialize Embeddings\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=openai.api_key)\n",
        "\n",
        "# Initialize ChromaDB\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "collection = chroma_client.get_or_create_collection(\"insurance_policy\")\n",
        "\n",
        "# Embed and store chunks\n",
        "for idx, row in df_exploded.iterrows():\n",
        "    chunk_text = row[\"Chunks\"]\n",
        "    vector = embedding_model.embed_documents([chunk_text])[0]\n",
        "    collection.add(\n",
        "        documents=[chunk_text],\n",
        "        metadatas=[{\"page\": row[\"Page No.\"], \"doc\": row[\"Document Name\"]}],\n",
        "        ids=[str(idx)]\n",
        "    )\n",
        "print(\"Embedding & storage complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzp2bLFytuxL",
        "outputId": "21ddabdc-d385-41de-befb-70d029cecede"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 0\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 3\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 4\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 6\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 6\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 7\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 7\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 8\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 9\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 9\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 10\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 10\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 11\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 11\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 12\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 12\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 13\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 13\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 14\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 14\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 15\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 15\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 16\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 16\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 17\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 17\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 18\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 18\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 19\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 19\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 20\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 20\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 21\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 21\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 22\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 22\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 23\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 23\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 24\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 24\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 25\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 25\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 26\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 26\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 27\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 27\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 28\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 28\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 29\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 29\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 30\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 30\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 31\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 31\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 32\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 32\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 33\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 33\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 34\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 34\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 35\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 35\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 36\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 36\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 37\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 37\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 38\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 38\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 39\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 39\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 40\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 40\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 41\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 41\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 42\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 42\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 43\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 43\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 44\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 44\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 45\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 45\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 46\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 46\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 47\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 47\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 48\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 48\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 49\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 49\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 50\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 50\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 51\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 51\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 52\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 52\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 53\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 53\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 54\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 54\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 55\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 55\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 56\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 56\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 57\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 57\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 58\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 58\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 59\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 59\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 60\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 60\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 61\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 61\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 62\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 62\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 63\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 63\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 64\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 64\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 65\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 65\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 66\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 66\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 67\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 67\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 68\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 68\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 69\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 69\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 70\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 70\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 71\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 71\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 72\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 72\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 73\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding & storage complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total documents stored in ChromaDB: {collection.count()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmvnsoauyh3n",
        "outputId": "7c1dd0ed-4bd4-4cd7-e851-44e7ec843c11"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total documents stored in ChromaDB: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **6.Implementing Query Search**\n",
        "\n",
        "\n",
        ">  To Retrieve Relevant Documents from Embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "8EKfuG5dJThe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ChromaDB Search\n",
        "vector_db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_model)\n",
        "\n",
        "def search_query(query, top_k=3):\n",
        "    \"\"\"\n",
        "    Searches the ChromaDB vector database for the most relevant chunks for the given query.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The search query.\n",
        "        top_k (int): The number of top results to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: Retrieved document chunks along with their similarity scores.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Generate embedding for the query\n",
        "        query_embedding = embedding_model.embed_query(query)\n",
        "\n",
        "        # Perform similarity search\n",
        "        results = vector_db.similarity_search_with_score(query, k=top_k)\n",
        "\n",
        "        # If no results are found, handle it gracefully\n",
        "        if not results:\n",
        "            print(f\"\\n No relevant documents found for query: {query}\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error during search: {e}\")\n",
        "        return []\n",
        "\n",
        "# Example Queries\n",
        "queries = [\n",
        "    \"What are the eligibility criteria for this policy?\",\n",
        "    \"How is the claim process handled?\",\n",
        "    \"What are the exclusions in this insurance policy?\"\n",
        "]\n",
        "\n",
        "# Get Top Results\n",
        "for query in queries:\n",
        "    results = search_query(query)\n",
        "\n",
        "    print(f\"\\n Query: {query}\")\n",
        "    if results:\n",
        "        for idx, (doc, score) in enumerate(results):\n",
        "            print(f\" Result {idx+1}: {doc.page_content[:200]}... (Score: {score:.4f})\")  # Display first 200 chars\n",
        "    else:\n",
        "        print(f\"No documents found for query: {query}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86F7jIE4JAWi",
        "outputId": "892094aa-a7ac-40c7-c1f6-00fb41cde92a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Query: What are the eligibility criteria for this policy?\n",
            " Result 1: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            " \n",
            "PART III - INDIVIDUAL REQUIREMENTS AND RIGHTS \n",
            "GC 6006 Section A - Eligibility, Page 1  \n",
            " \n",
            "PART III - INDIVIDUAL REQUIREMENTS AND RIGHTS \n",
            " ... (Score: 0.3231)\n",
            " Result 2: (1) Employees: \n",
            " \n",
            "- at least 75% of all eligible employees must enroll; \n",
            " \n",
            "(2) Dependents: \n",
            " \n",
            "- maintain a Dependent participation of at least 75% of eligible Dependents; and \n",
            " \n",
            "d. if the Member is to... (Score: 0.3375)\n",
            " Result 3: consent to the change. \n",
            " \n",
            " \n",
            "Article 3 - Policyholder Eligibility Requirements \n",
            " \n",
            "To be an eligible group and to remain an eligible group, the Policyholder must:... (Score: 0.3378)\n",
            "\n",
            " Query: How is the claim process handled?\n",
            " Result 1: ERISA permits up to 45 days from receipt of claim for processing the claim.  If a claim cannot \n",
            "be processed due to incomplete information, The Principal will send a Written explanation prior \n",
            "to the ... (Score: 0.3309)\n",
            " Result 2: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            " \n",
            "PART IV - BENEFITS \n",
            "GC 6018  Section D - Claim Procedures, Page 2  \n",
            " \n",
            "A claimant may request an appeal of a claim denial by Written request... (Score: 0.3364)\n",
            " Result 3: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            " \n",
            "PART IV - BENEFITS \n",
            "GC 6018  Section D - Claim Procedures, Page 1  \n",
            " \n",
            "Section D - Claim Procedures \n",
            " \n",
            " \n",
            "Article 1 - Notice of Claim \n",
            " \n",
            "Writ... (Score: 0.3404)\n",
            "\n",
            " Query: What are the exclusions in this insurance policy?\n",
            " Result 1: coverage by purchasing an individual policy of life insurance under these terms: \n",
            " \n",
            "(1) The Member will not be required to submit Proof of Good Health. \n",
            "(2) The policy will be for life insurance only.... (Score: 0.3187)\n",
            " Result 2: (2) If insurance is requested under this Group Policy by a Member that was eligible under \n",
            "the Prior Policy, but elected to waive coverage under the Prior Policy. \n",
            "(3) If a Member has failed to provid... (Score: 0.3357)\n",
            " Result 3: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            "      PART IV - BENEFITS \n",
            "GC 6015  Section B - Member Accidental Death and \n",
            "Dismemberment Insurance, Page 3 \n",
            " \n",
            " \n",
            " \n",
            "Exposure \n",
            " \n",
            "Exposure to th... (Score: 0.3415)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.  Rerank Results using Cross-Encoder**"
      ],
      "metadata": {
        "id": "Aq-Iw2RwB8H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# Load cross-encoder for reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "def search_query(query, top_k=10):\n",
        "    # Correct embedding for OpenAIEmbeddings\n",
        "    query_embedding = embedding_model.embed_query(query)  # Fix: Use `embed_query()`\n",
        "\n",
        "    # Retrieve initial results from ChromaDB\n",
        "    results = vector_db.similarity_search_with_score(query, k=top_k)\n",
        "\n",
        "    if not results:\n",
        "        print(f\"\\n No relevant documents found for query: {query}\")\n",
        "        return []\n",
        "\n",
        "    # Extract text and similarity scores\n",
        "    retrieved_texts = [doc.page_content for doc, score in results]\n",
        "    scores = [score for doc, score in results]\n",
        "\n",
        "    # Rerank using Cross-Encoder\n",
        "    rerank_scores = cross_encoder.predict([[query, text] for text in retrieved_texts])\n",
        "\n",
        "    # Sort results based on reranker scores\n",
        "    sorted_results = sorted(zip(retrieved_texts, rerank_scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select top-k reranked results\n",
        "    top_reranked = sorted_results[:3]\n",
        "\n",
        "    print(f\"\\n🔎 Query: {query}\")\n",
        "    for idx, (doc, score) in enumerate(top_reranked):\n",
        "        print(f\"🔹 Retrieved Chunk {idx+1}: {doc[:500]}... (Re-Rank Score: {score:.4f})\")\n",
        "\n",
        "    return top_reranked\n"
      ],
      "metadata": {
        "id": "4Vc4y_uq04uE"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Generate Final Answer using GPT**"
      ],
      "metadata": {
        "id": "8fX8ZpXNDHDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query, context):\n",
        "    \"\"\"\n",
        "    Generates an answer using GPT-4 based on the retrieved document context.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The user’s question.\n",
        "        context (str): The retrieved relevant document text.\n",
        "\n",
        "    Returns:\n",
        "        str: The AI-generated answer.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure the context is not empty to avoid irrelevant answers\n",
        "        if not context.strip():\n",
        "            return \" No relevant information found in the document to answer this query.\"\n",
        "\n",
        "        # Define system role and user query separately for structured interaction\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI assistant answering questions about an insurance policy document. Use the provided document context to answer accurately.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Context: {context}\\nUser Query: {query}\\n\\nPlease provide a clear, detailed, and helpful response.\"}\n",
        "        ]\n",
        "\n",
        "        # Call GPT-4 API to generate a response\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error generating answer: {e}\"\n",
        "\n",
        "# Example Queries\n",
        "queries = [\n",
        "    \"What are the eligibility criteria for this policy?\",\n",
        "    \"How is the claim process handled?\",\n",
        "    \"What are the exclusions in this insurance policy?\"\n",
        "]\n",
        "\n",
        "# Generate Answers for Queries\n",
        "for query in queries:\n",
        "    retrieved_docs = search_query(query, top_k=3)  # Retrieve relevant documents\n",
        "    # Modify this line to extract the text from the tuples:\n",
        "    combined_context = \" \".join([doc for doc, score in retrieved_docs]) if retrieved_docs else \"\"\n",
        "\n",
        "    answer = generate_answer(query, combined_context)\n",
        "\n",
        "    print(f\"\\n🔎 Query: {query}\")\n",
        "    print(f\"💬 Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtEtO6EIcEwU",
        "outputId": "fcd478d4-405e-4278-e9e1-6084ee57440c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔎 Query: What are the eligibility criteria for this policy?\n",
            "🔹 Retrieved Chunk 1: consent to the change. \n",
            " \n",
            " \n",
            "Article 3 - Policyholder Eligibility Requirements \n",
            " \n",
            "To be an eligible group and to remain an eligible group, the Policyholder must:... (Re-Rank Score: 4.1368)\n",
            "🔹 Retrieved Chunk 2: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            " \n",
            "PART III - INDIVIDUAL REQUIREMENTS AND RIGHTS \n",
            "GC 6006 Section A - Eligibility, Page 1  \n",
            " \n",
            "PART III - INDIVIDUAL REQUIREMENTS AND RIGHTS \n",
            " \n",
            " \n",
            "Section A - Eligibility \n",
            " \n",
            " \n",
            "Article 1 - Member Life Insurance \n",
            " \n",
            "A person will be eligible for Member Life Insurance on the date the person completes 30 \n",
            "consecutive days of continuous Active Work with the Policyholder as a Member.... (Re-Rank Score: 4.0769)\n",
            "🔹 Retrieved Chunk 3: (1) Employees: \n",
            " \n",
            "- at least 75% of all eligible employees must enroll; \n",
            " \n",
            "(2) Dependents: \n",
            " \n",
            "- maintain a Dependent participation of at least 75% of eligible Dependents; and \n",
            " \n",
            "d. if the Member is to contribute no part of the premium, 100% of eligible employees and \n",
            "Dependents must enroll. \n",
            " \n",
            " \n",
            "Article 4 - Policy Incontestability \n",
            " \n",
            "In the absence of fraud, after this Group Pol icy has been in force two years, The Principal may \n",
            "not contest its validity except for nonpayment of premium.... (Re-Rank Score: -1.1393)\n",
            "\n",
            "🔎 Query: What are the eligibility criteria for this policy?\n",
            "💬 Answer: For a person to be eligible for Member Life Insurance under this policy, they have to complete 30 consecutive days of continuous Active Work with the Policyholder as a member. There are also specific conditions that need to be met:\n",
            "\n",
            "1. Employees: At least 75% of all eligible employees must enroll for the policy.\n",
            "   \n",
            "2. Dependents: It is required to maintain a participation of at least 75% of eligible Dependents. \n",
            "\n",
            "3. If the Member (employee/individual) is not contributing any part of the premium, then 100% of eligible employees and their Dependents must enroll in the policy. \n",
            "\n",
            "This policy was updated on January 1, 2014, so these requirements may be subject to changes agreed upon after that date. \n",
            "\n",
            "Finally, keep in mind that after this Group Policy has been in force for two years, The Principal may not contest its validity except for nonpayment of the premium, assuming no fraudulent activity.\n",
            "\n",
            "🔎 Query: How is the claim process handled?\n",
            "🔹 Retrieved Chunk 1: ERISA permits up to 45 days from receipt of claim for processing the claim.  If a claim cannot \n",
            "be processed due to incomplete information, The Principal will send a Written explanation prior \n",
            "to the expiration of the 45 days.  The claimant is then allowed up to 45 days to provide all \n",
            "additional information requested.  The Principal is permitted two 30 -day extensions for \n",
            "processing an incomplete claim.  Written notification will be sent to the claimant regarding the \n",
            "extension.... (Re-Rank Score: 0.1583)\n",
            "🔹 Retrieved Chunk 2: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            " \n",
            "PART IV - BENEFITS \n",
            "GC 6018  Section D - Claim Procedures, Page 2  \n",
            " \n",
            "A claimant may request an appeal of a claim denial by Written request to The Principal within \n",
            "180 days of receipt of notice of the denial.  The Principal will make a full and fair review of the \n",
            "claim.  The Principal may require additional information to make the review.  The Principal will... (Re-Rank Score: -1.7221)\n",
            "🔹 Retrieved Chunk 3: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            " \n",
            "PART IV - BENEFITS \n",
            "GC 6018  Section D - Claim Procedures, Page 1  \n",
            " \n",
            "Section D - Claim Procedures \n",
            " \n",
            " \n",
            "Article 1 - Notice of Claim \n",
            " \n",
            "Written notice must be sent to The Principal by or for a Member or Dependent who wishes to file \n",
            "claim for benefits under this Group Policy.  This notice must be sent within 20 days after the date \n",
            "of the loss for which claim is being made.  Failure to give notice within the time specified will... (Re-Rank Score: -4.2684)\n",
            "\n",
            "🔎 Query: How is the claim process handled?\n",
            "💬 Answer: The claim process is handled as follows:\n",
            "\n",
            "1. A written notice must be sent by or for a member or dependent who wishes to file a claim for benefits under this Group Policy to The Principal. This notice should be sent within 20 days after the date of the loss for which the claim is being made.\n",
            "\n",
            "2. ERISA permits up to 45 days from the receipt of the claim for processing the claim.\n",
            "\n",
            "3. If a claim cannot be processed due to incomplete information, The Principal will send a written explanation before the 45 days period expires.\n",
            "\n",
            "4. The claimant then has up to 45 days to provide all additional information requested.\n",
            "\n",
            "5. The Principal is allowed two 30-day extensions for processing an incomplete claim. Written notification will be sent to the claimant about the extension.\n",
            "\n",
            "6. If a claim is denied, the claimant may request an appeal of this decision via written request to The Principal within 180 days of receiving the denial notice.\n",
            "\n",
            "7. The Principal then conducts a full and fair review of the claim and may require additional information to complete the review.\n",
            "\n",
            "Please note that failure to provide notice within the specified time can result in complications or denial of the claim.\n",
            "\n",
            "🔎 Query: What are the exclusions in this insurance policy?\n",
            "🔹 Retrieved Chunk 1: (2) If insurance is requested under this Group Policy by a Member that was eligible under \n",
            "the Prior Policy, but elected to waive coverage under the Prior Policy. \n",
            "(3) If a Member has failed to provide required Proof of Good Health or has been refused \n",
            "insurance under this Group Policy at any prior time. \n",
            "(4) If a Member elects to terminate insurance and, more than 31 days later, requests to be \n",
            "insured again. \n",
            "(5) If, on the date a Member becomes eligible, fewer than five Members are insured.... (Re-Rank Score: -2.9272)\n",
            "🔹 Retrieved Chunk 2: coverage by purchasing an individual policy of life insurance under these terms: \n",
            " \n",
            "(1) The Member will not be required to submit Proof of Good Health. \n",
            "(2) The policy will be for life insurance only.  No disabilit y or other benefits will be \n",
            "included. \n",
            "(3) The policy will be on one of the forms, other than term insurance, then issued by The \n",
            "Principal to persons in the risk class to which the Member belongs on the individual \n",
            "policy's effective date.... (Re-Rank Score: -3.8340)\n",
            "🔹 Retrieved Chunk 3: This policy has been updated effective  January 1, 2014 \n",
            " \n",
            "      PART IV - BENEFITS \n",
            "GC 6015  Section B - Member Accidental Death and \n",
            "Dismemberment Insurance, Page 3 \n",
            " \n",
            " \n",
            " \n",
            "Exposure \n",
            " \n",
            "Exposure to the elements will be presumed to be an injury if: \n",
            " \n",
            "a. such exposure is due to an accidental bodily injury; and \n",
            " \n",
            "b. within 365 days after the injury, the Member incurs a loss that is the result of the exposure; \n",
            "and \n",
            " \n",
            "c. this Group Policy would have covered the injury resulting from the accident.... (Re-Rank Score: -5.1268)\n",
            "\n",
            "🔎 Query: What are the exclusions in this insurance policy?\n",
            "💬 Answer: Based on the document context provided, the following exclusions can be identified in this insurance policy:\n",
            "\n",
            "1. If a member was eligible under the Prior Policy but chose to waive coverage under the Prior Policy and is now requesting insurance under this Group Policy.\n",
            "\n",
            "2. If a member has failed to provide required Proof of Good Health or had been previously denied insurance under this Group Policy.\n",
            "\n",
            "3. If a member decides to terminate their insurance and then requests to be insured again more than 31 days later.\n",
            "\n",
            "4. If, on the date a member becomes eligible, there are fewer than five members insured.\n",
            "\n",
            "Remember, these exclusions pertain to the specific context and language provided in the excerpt of the policy. Always refer to your complete policy document for a full understanding of coverage and exclusions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4PNj1lN16zso"
      }
    }
  ]
}